notes.txt
=========

Dev notes for the spsms (Solace Pub Sub Monitor) container project.

AWS AMI Instances
=================

Glyn set up two AWS ami instances with 
docker 
(Version:          19.03.13-ce)
java
(java version "1.8.0_131")
installed.

SolacePubSubMonitor_6.1.0.0.zip
was installed on 
/home/ec2-user/rtv

and unpacked (unzip -a) into 
/home/ec2-user/rtv/SolacePubSubMonitor

commands were verified and run under /home/ec2-user/rtv/SolacePubSubMonitor/bin

The instances (and external/ internal IP's are)

name                External IP         INTERNAL IP
====                =============       ===========

PRIMARYHOST         18.234.128.85       172.31.36.95
SECONDARYHOST       18.212.174.66       172.31.42.171


Configuring HA 
===============

~/.bashrc_profile on both machines were modified to include


#
# Set up environment variables for HA operation
#
# use internal IP  adresses as it is just for dataserver -> dataserver communication
#

export PRIMARYHOST=172.31.36.95
export BACKUPHOST=172.31.42.171


such that 

printenv | grep HOST
HOSTNAME=ip-172-31-36-95.ec2.internal
BACKUPHOST=172.31.42.171
PRIMARYHOST=172.31.36.95


(the dataservers talk to each other using the values of PRIMARYHOST and BACKUPHOST env vars)

Next update the update_wars.sh script to use these values , thus

# is this true for containers ? its where the apache instance runs
HOST=localhost


# Set HA_HOST to the hostname of the backup data server.

#HA_HOST=


# Edit these values for High Availability.
# Set HA_HOST to the hostname of the backup data server.
# Set HA_DISPLAYHOST to the hostname of the backup display server.
# Set HA_FAILBACK to true to automatically reconnect to the primary display server.

HA_HOST=$BACKUPHOST
HA_DISPLAYHOST=$BACKUPHOST
HA_FAILBACK=true



rebuild the wars 

./update_wars.sh

and copy the updates war files to the apache webserver webapps directory

cp *.war ../../apache-tomcat-*/webapps

cp *.war /home/ec2-user/rtv/SolacePubSubMonitor/apache-tomcat-8.5.69-sl/webapps


then on the primary in 
/home/ec2-user/rtv/SolacePubSubMonitor/bin

./start_servers.sh -haprimary -verbose

on the secondary 
./start_servers.sh -habackup -verbose


confirm with 
jps
or 
./status_servers.sh

CHECKING HA
===========

killing dataserver with kill -9

restarting dataserver with stop_servers.sh / start_servers.sh


then looking in 

/home/ec2-user/rtv/SolacePubSubMonitor/projects/rtvie[ec2-user@ip-172-31-36-95 logs]$ cat dataserver.log | grep standbyMode
2021-08-09 23:17:34,463 INFO  main - [rtview] standbyModeChanged: 0
w-server/logs


[ec2-user@ip-172-31-36-95 logs]$ cat dataserver.log | grep HA
2021-08-09 23:16:53,724 INFO  main - [rtview] Starting as primary HA data server accessible via //172.31.36.95:4178,//172.31.42.171:4178
2021-08-09 23:17:33,521 INFO  main - [rtview] DataServerHA: connected to 172.31.42.171:4178
2021-08-09 23:17:33,573 INFO  main - [rtview] DataServerHA: run as primary server, 172.31.42.171:4178 has lower priority than this server
2021-08-09 23:32:48,618 INFO  GmsClientReceiverThread-172.31.42.171:4178 - [rtview] DataServerHA: error receiving message: java.io.EOFException (172.31.42.171:4178)
[

2021-08-09 23:01:05,954 INFO  main - [rtview] Starting as backup HA data server accessible via //172.31.36.95:4178,//172.31.42.171:4178
2021-08-09 23:01:32,792 INFO  main - [rtview] DataServerHA: connected to 172.31.36.95:4178
2021-08-09 23:01:32,845 INFO  main - [rtview] DataServerHA: run as backup server, 172.31.36.95:4178 has higher priority than this server
2021-08-09 23:12:56,006 INFO  GmsClientReceiverThread-172.31.36.95:4178 - [rtview] DataServerHA: error receiving message: java.io.EOFException (172.31.36.95:4178)
2021-08-09 23:12:56,010 INFO  GmsClientReceiverThread-172.31.36.95:4178 - [rtview] DataServerHA: becoming primary server, lost connection to primary server 172.31.36.95:4178
2021-08-09 23:17:33,615 INFO  RtvClientReader9-172.31.36.95:54242 - [rtview] DataServerHA: resigning as primary server, got standby directive from other server 172.31.36.95:4178
2021-08-09 23:17:36,838 INFO  GmsClientReceiverThread-172.31.36.95:4178 - [rtview] DataServerHA: re-connected to 172.31.36.95:4178

[ec2-user@ip-172-31-42-171 logs]$ cat dataserver.log | grep  standbyMode
2021-08-09 23:12:56,780 INFO  GmsClientReceiverThread-172.31.36.95:4178 - [rtview] standbyModeChanged: 0
2021-08-09 23:17:33,706 INFO  RtvClientReader9-172.31.36.95:54242 - [rtview] standbyModeChanged: 1


Java base container images
==========================

install and try using 

docker run amazoncorretto:11 java -version
docker run openjdk:11 java -version
docker run adoptopenjdk:11 java -version
docker run adoptopenjdk/openjdk11 java -version
docker run adoptopenjdk/openjdk11:slim java -version

and then 
docker images
for

REPOSITORY               TAG                 IMAGE ID            CREATED             SIZE
adoptopenjdk/openjdk11   slim                c0afc17b4458        32 hours ago        371MB
adoptopenjdk/openjdk11   latest              7fdb379b7d9a        32 hours ago        437MB
amazoncorretto           11                  2b27f3c83c92        7 days ago          445MB
adoptopenjdk             11                  6786c6dbd92b        2 weeks ago         437MB
openjdk                  11                  e782567c0965        2 weeks ago         648MB

using 11 as it is latest, supported  and container aware .. 




docker-compose
==============

installed missing docker-compose using instructions at

https://gist.github.com/npearce/6f3c7826c7499587f00957fee62f8ee9

sudo curl -L https://github.com/docker/compose/releases/latest/download/docker-compose-$(uname -s)-$(uname -m) -o /usr/local/bin/docker-compose
sudo chmod +x /usr/local/bin/docker-compose
docker-compose -version

(docker-compose version 1.29.2, build 5becea4c)


initial git directories
=======================

created initial got directories

/home/m/src/dev/spsm_notes ( for this) spsm_notes.txt

and 

/home/m/src/dev/spsm  ( for Dockerfile, docker-compose.yml, README.md and src/run.sh placeholders )


Conversation with Glyn moved the defintion of HA to 3 containers on single machine controlled by a docker-compose files

1) tomcat
2) haprimary
3) habackup

A tomcat subdirectory and associated Dockerfile and docker-compose file were created to manage the creation of 
the tomcat container

it was decided that the wars would be build externally and copied into the tomcat container during the build process

It was alkso discovered that the default landing page etc were disabled by default , and can be reinstated by

        # Add the missing webapps disabled by default for security
        RUN cp -r webapps.dist/* webapps/


uses the default tomcat port of 8080 - other values will require configuration.


On the primary and backup subdirectory

initially used place holder scripts for  the data servers etc so the docker compose file could be exercised.

Usual items encountered

needed to add net-tools to containers for keying code to avoid run time errors

added tini to containers main script to handle signals (evidenced by much faster shutdown)

no-op scripts addded to supress tomcat inside non tomcat containers

fun and games with environment variables, service names and hostnames to deal with assumptions made in 
primary and secondary deployements to deal with container / docker compose implementations

and tail the dataserver log file so we can use docker log commands like

docker-compose log [haprimary|habackup|tomcat]

so we can see that failover appears to work with

docker-compose update
docker-compose log haprimary 
docker-compose log habackup 
docker-compose stop haprimary 
docker-compose start ha-primary 

(using this as a test case)

There is potential to use the docker-compose restart policies 
but that is almost out of scope ...


Still to be done ...

trying to work out what is going on with the  war files such that apache on a different machine ( container )

works as expected ...


------------

apache tomcat needs to be configured like the SL instance

So copy across the changes as described in  README_RTVIEW.txt

(these could be made more fine grained in the tomcat/Dockerfile)

key changes used in the update wars script

# Set HA_HOST to the hostname of the backup data server.  

HOST=haprimary
HA_HOST=habackup

fun and games with  Dockerfile COPY operation - source must be in DIR tree - so we need a local copy of  SolacePubSubMonitor

when configured correctly - tomcat behaves as expected

war files updated to use the (docker local dns service names / hosts haprimary and habackup) - no ports need to be exposed thanks to the magic of docker networking

---

haprimary / habackup persistence

lots of fun and games with the small details of persistence / mounted volumes

mounted volumes overwite / replace what was at the mount point ...

so just mounting an (empty) volume had the effect of blanking out / replacing was there 

so we need to pre-populate what went there before

also file permissions need to be set so the container user ID can update the mounted files if neccesary

also seems updates can only happen at the level of the mounted volume ( projects didn't seem to work , hence mount at rtview-server)
discovered a temp directory - so mounted filesystem for that would be slower / not a good idea.

made a lib directiry for classpath / added jars ( e.g. external database)

hence

setup_volumes.sh script

---

Now that is all set up - we get perisistece of settings ... effect

---

TBD

1) add external database - show use and persistence of setup for e.g. external MySql

use cases

==============

1) document and exercise setup from scratch 

(unzip -a SolacePubSubMonitor , once in root , once in tomcat)

edit updates_wars.sh , run  and copy updated warfiles into warfiles directory 

docker-compose up --build -d ( first time)

or 

docker-compose build
docker-compose up -d


docker-compose down

docker-compose up -d

setup

then show effects of 
docker-compose logs [-f] [haprimary|habackup|tomcat]


failover by

docker-compose stop haprimary ...
docker-compose start haprimary 


persistence by 

docker-compose ps

docker-compose down ...

docker-compose ps ( nothing up my sleve )

docker-compose up 


voila ...


( see if there are any further use cases , examples requred etc ...)

also useful commands like

docker-compose logs -f <service>

docker-compose exec <service> /bin/bashrc_profile

docker-compose-images



------

Database details

database-mysqlmicro.c5krfqqmddsm.us-east-1.rds.amazonaws.com

user: admin
password: m password

How to connect:

https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_CommonTasks.Connect.html

provides:

The connection information for a DB instance includes its endpoint, port, and a valid database user, such as the master user. For example, for a MySQL DB instance, suppose that the endpoint value is mydb.123456789012.us-east-1.rds.amazonaws.com. In this case, the port value is 3306, and the database user is admin. Given this information, you specify the following values in a connection string:

·         For host or host name or DNS name, specify mydb.123456789012.us-east-1.rds.amazonaws.com.

·         For port, specify 3306.

·         For user, specify admin.


downloaded latest mysql j/connnector 8  ( 8.0.26 ) jar from

https://dev.mysql.com/downloads/connector/j/?os=26

driver class, from  https://dev.mysql.com/doc/connector-j/8.0/en/connector-j-reference-driver-name.html

is 

com.mysql.cj.jdbc.Driver

confirmed in Squirrel Sql

e.g.
driver 

claspath for jar  () 

URL = 

jdbc:mysql://database-mysqlmicro.c5krfqqmddsm.us-east-1.rds.amazonaws.com:3306/RTVHISTORY?sessionVariables=sql_mode=ANSI_QUOTES

for for historian 


#########################
# HISTORIAN
collector.sl.rtview.sql.sqldb=RTVHISTORY admin 013370134501349013420129101291013310134201342 jdbc:mysql://database-mysqlmicro.c5krfqqmddsm.us-east-1.rds.amazonaws.com:3306/RTVHISTORY?sessionVariables=sql_mode=ANSI_QUOTES com.mysql.cj.jdbc.Driver - false true
historian.sl.rtview.historian.driver=com.mysql.cj.jdbc.Driver
historian.sl.rtview.historian.url=jdbc:mysql://database-mysqlmicro.c5krfqqmddsm.us-east-1.rds.amazonaws.com:3306/RTVHISTORY?sessionVariables=sql_mode=ANSI_QUOTES
historian.sl.rtview.historian.username=admin
historian.sl.rtview.historian.password=013370134501349013420129101291013310134201342
historian.sl.rtview.cp=/rtv/SolacePubSubMonitor/projects/lib/*
collector.sl.rtview.cp=/rtv/SolacePubSubMonitor/projects/lib/*


Setup Database
==============

RTVHISTORY 
----------

conect to database

CREATE DATABASE RTVHISTORY

USE RTVHISTORY

execute contents of 

SolacePubSubMonitor/rtvapm/solmon/dbconfig

e.g.

create_solmon_history_tables_mysql.sql

ALERTDEFS 
---------

conect to database

CREATE DATABASE ALERTDEFS

USE ALERTDEFS

execute contents of 

SolacePubSubMonitor/rtvapm/common/dbconfig

e.g.

create_common_alertdefs_tables_mysql.sql


So shown container connecting to external database working

SYSLOG
======

we need to expose a (listening) port for SYSLOG

so expose the port in the Dockerfile


# expose port used by syslog listener
EXPOSE 10601


But both HA containers run on the same host  ... how can we deconflict the port conflict ?

By mapping the ports in the docker compose file 


haprimary:
ports:
      #exposed port for syslog (primary) on <this_host>:10601)
      - 10601:10601


habackup:
ports:
      #exposed port for syslog (backup on <this_host>:10602)
      - 10602:10601      

































